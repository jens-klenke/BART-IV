
@article{hahn_bayesian_2020,
	title = {Bayesian {Regression} {Tree} {Models} for {Causal} {Inference}: {Regularization}, {Confounding}, and {Heterogeneous} {Effects} (with {Discussion})},
	volume = {15},
	issn = {1936-0975, 1931-6690},
	shorttitle = {Bayesian {Regression} {Tree} {Models} for {Causal} {Inference}},
	url = {https://projecteuclid.org/journals/bayesian-analysis/volume-15/issue-3/Bayesian-Regression-Tree-Models-for-Causal-Inference--Regularization-Confounding/10.1214/19-BA1195.full},
	doi = {10.1214/19-BA1195},
	abstract = {This paper presents a novel nonlinear regression model for estimating heterogeneous treatment effects, geared specifically towards situations with small effect sizes, heterogeneous effects, and strong confounding by observables. Standard nonlinear regression models, which may work quite well for prediction, have two notable weaknesses when used to estimate heterogeneous treatment effects. First, they can yield badly biased estimates of treatment effects when fit to data with strong confounding. The Bayesian causal forest model presented in this paper avoids this problem by directly incorporating an estimate of the propensity function in the specification of the response model, implicitly inducing a covariate-dependent prior on the regression function. Second, standard approaches to response surface modeling do not provide adequate control over the strength of regularization over effect heterogeneity. The Bayesian causal forest model permits treatment effect heterogeneity to be regularized separately from the prognostic effect of control variables, making it possible to informatively “shrink to homogeneity”. While we focus on observational data, our methods are equally useful for inferring heterogeneous treatment effects from randomized controlled experiments where careful regularization is somewhat less complicated but no less important. We illustrate these benefits via the reanalysis of an observational study assessing the causal effects of smoking on medical expenditures as well as extensive simulation studies.},
	number = {3},
	urldate = {2021-12-09},
	journal = {Bayesian Analysis},
	author = {Hahn, P. Richard and Murray, Jared S. and Carvalho, Carlos M.},
	month = sep,
	year = {2020},
	note = {Publisher: International Society for Bayesian Analysis},
	keywords = {\_tablet, 62-07, 62F15, 62J02, Bayesian, Causal inference, heterogeneous treatment effects, machine learning, predictor-dependent priors, regression trees, regularization, shrinkage},
	pages = {965--1056},
	file = {Hahn et al_2020_Bayesian Regression Tree Models for Causal Inference.pdf:/Users/lennardmassmann/Zotero/storage/6SAF2ADD/Hahn et al_2020_Bayesian Regression Tree Models for Causal Inference.pdf:application/pdf;Snapshot:/Users/lennardmassmann/Zotero/storage/4KCU5T4Q/19-BA1195.html:text/html},
}




@article{linero_bayesian_2018,
	title = {Bayesian {Regression} {Tree} {Ensembles} that {Adapt} to {Smoothness} and {Sparsity}},
	volume = {80},
	issn = {1369-7412, 1467-9868},
	url = {https://academic.oup.com/jrsssb/article/80/5/1087/7048381},
	doi = {10.1111/rssb.12293},
	abstract = {Ensembles of decision trees are a useful tool for obtaining ﬂexible estimates of regression functions. Examples of these methods include gradient-boosted decision trees, random forests and Bayesian classiﬁcation and regression trees.Two potential shortcomings of tree ensembles are their lack of smoothness and their vulnerability to the curse of dimensionality. We show that these issues can be overcome by instead considering sparsity inducing soft decision trees in which the decisions are treated as probabilistic. We implement this in the context of the Bayesian additive regression trees framework and illustrate its promising performance through testing on benchmark data sets. We provide strong theoretical support for our methodology by showing that the posterior distribution concentrates at the minimax rate (up to a logarithmic factor) for sparse functions and functions with additive structures in the high dimensional regime where the dimensionality of the covariate space is allowed to grow nearly exponentially in the sample size. Our method also adapts to the unknown smoothness and sparsity levels, and can be implemented by making minimal modiﬁcations to existing Bayesian additive regression tree algorithms.},
	language = {en},
	number = {5},
	urldate = {2023-08-17},
	journal = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
	author = {Linero, Antonio R. and Yang, Yun},
	month = nov,
	year = {2018},
	pages = {1087--1110},
	file = {Linero und Yang - 2018 - Bayesian Regression Tree Ensembles that Adapt to S.pdf:/Users/lennardmassmann/Zotero/storage/LMVKWLFV/Linero und Yang - 2018 - Bayesian Regression Tree Ensembles that Adapt to S.pdf:application/pdf},
}

@article{linero_bayesian_2018-1,
	title = {Bayesian {Regression} {Trees} for {High}-{Dimensional} {Prediction} and {Variable} {Selection}},
	volume = {113},
	issn = {0162-1459},
	url = {https://doi.org/10.1080/01621459.2016.1264957},
	doi = {10.1080/01621459.2016.1264957},
	abstract = {Decision tree ensembles are an extremely popular tool for obtaining high-quality predictions in nonparametric regression problems. Unmodified, however, many commonly used decision tree ensemble methods do not adapt to sparsity in the regime in which the number of predictors is larger than the number of observations. A recent stream of research concerns the construction of decision tree ensembles that are motivated by a generative probabilistic model, the most influential method being the Bayesian additive regression trees (BART) framework. In this article, we take a Bayesian point of view on this problem and show how to construct priors on decision tree ensembles that are capable of adapting to sparsity in the predictors by placing a sparsity-inducing Dirichlet hyperprior on the splitting proportions of the regression tree prior. We characterize the asymptotic distribution of the number of predictors included in the model and show how this prior can be easily incorporated into existing Markov chain Monte Carlo schemes. We demonstrate that our approach yields useful posterior inclusion probabilities for each predictor and illustrate the usefulness of our approach relative to other decision tree ensemble approaches on both simulated and real datasets. Supplementary materials for this article are available online.},
	number = {522},
	urldate = {2023-10-12},
	journal = {Journal of the American Statistical Association},
	author = {Linero, Antonio R.},
	month = apr,
	year = {2018},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/01621459.2016.1264957},
	keywords = {Bayesian additive regression trees, Bayesian learning, Decision trees, Nonparametric regression, Random forests, Variable selection},
	pages = {626--636},
	file = {Linero_2018_Bayesian Regression Trees for High-Dimensional Prediction and Variable Selection.pdf:/Users/lennardmassmann/Zotero/storage/CVAXRUX7/Linero_2018_Bayesian Regression Trees for High-Dimensional Prediction and Variable Selection.pdf:application/pdf},
}

@article{bargagli-stoffi_heterogeneous_2022,
	title = {Heterogeneous causal effects with imperfect compliance: {A} {Bayesian} machine learning approach},
	volume = {16},
	issn = {1932-6157, 1941-7330},
	shorttitle = {Heterogeneous causal effects with imperfect compliance},
	url = {https://projecteuclid.org/journals/annals-of-applied-statistics/volume-16/issue-3/Heterogeneous-causal-effects-with-imperfect-compliance--A-Bayesian-machine/10.1214/21-AOAS1579.full},
	doi = {10.1214/21-AOAS1579},
	abstract = {This paper introduces an innovative Bayesian machine learning algorithm to draw interpretable inference on heterogeneous causal effects in the presence of imperfect compliance (e.g., under an irregular assignment mechanism). We show, through Monte Carlo simulations, that the proposed Bayesian Causal Forest with Instrumental Variable (BCF-IV) methodology outperforms other machine learning techniques tailored for causal inference in discovering and estimating the heterogeneous causal effects while controlling for the familywise error rate (or, less stringently, for the false discovery rate) at leaves’ level. BCF-IV sheds a light on the heterogeneity of causal effects in instrumental variable scenarios and, in turn, provides the policy-makers with a relevant tool for targeted policies. Its empirical application evaluates the effects of additional funding on students’ performances. The results indicate that BCF-IV could be used to enhance the effectiveness of school funding on students’ performance.},
	number = {3},
	urldate = {2024-07-25},
	journal = {The Annals of Applied Statistics},
	author = {Bargagli-Stoffi, Falco J. and Witte, Kristof De and Gnecco, Giorgio},
	month = sep,
	year = {2022},
	note = {Publisher: Institute of Mathematical Statistics},
	keywords = {Causal inference, Heterogeneous effects, instrumental variable, Interpretable machine learning, school funding, students’ performance},
	pages = {1986--2009},
	file = {Bargagli-Stoffi et al_2022_Heterogeneous causal effects with imperfect compliance.pdf:/Users/lennardmassmann/Zotero/storage/LBR9UZJL/Bargagli-Stoffi et al_2022_Heterogeneous causal effects with imperfect compliance.pdf:application/pdf},
}

@article{caron_shrinkage_2022,
	title = {Shrinkage {Bayesian} {Causal} {Forests} for {Heterogeneous} {Treatment} {Effects} {Estimation}},
	volume = {31},
	issn = {1061-8600},
	url = {https://doi.org/10.1080/10618600.2022.2067549},
	doi = {10.1080/10618600.2022.2067549},
	abstract = {This article develops a sparsity-inducing version of Bayesian Causal Forests, a recently proposed nonparametric causal regression model that employs Bayesian Additive Regression Trees and is specifically designed to estimate heterogeneous treatment effects using observational data. The sparsity-inducing component we introduce is motivated by empirical studies where not all the available covariates are relevant, leading to different degrees of sparsity underlying the surfaces of interest in the estimation of individual treatment effects. The extended version presented in this work, which we name Shrinkage Bayesian Causal Forest, is equipped with an additional pair of priors allowing the model to adjust the weight of each covariate through the corresponding number of splits in the tree ensemble. These priors improve the model’s adaptability to sparse data generating processes and allow to perform fully Bayesian feature shrinkage in a framework for treatment effects estimation, and thus to uncover the moderating factors driving heterogeneity. In addition, the method allows prior knowledge about the relevant confounding covariates and the relative magnitude of their impact on the outcome to be incorporated in the model. We illustrate the performance of our method in simulated studies, in comparison to Bayesian Causal Forest and other state-of-the-art models, to demonstrate how it scales up with an increasing number of covariates and how it handles strongly confounded scenarios. Finally, we also provide an example of application using real-world data. Supplementary materials for this article are available online.},
	number = {4},
	urldate = {2024-07-25},
	journal = {Journal of Computational and Graphical Statistics},
	author = {Caron, Alberto and Baio, Gianluca and Manolopoulou, Ioanna},
	month = oct,
	year = {2022},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/10618600.2022.2067549},
	keywords = {Bayesian nonparametrics, Causal inference, Heterogeneous treatment effects, Machine learning, Observational studies, Tree ensembles},
	pages = {1202--1214},
	file = {Caron et al_2022_Shrinkage Bayesian Causal Forests for Heterogeneous Treatment Effects Estimation.pdf:/Users/lennardmassmann/Zotero/storage/A4GKK75T/Caron et al_2022_Shrinkage Bayesian Causal Forests for Heterogeneous Treatment Effects Estimation.pdf:application/pdf},
}
